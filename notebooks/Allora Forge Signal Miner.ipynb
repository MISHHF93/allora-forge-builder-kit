{"cells": [{"cell_type": "markdown", "id": "ecaec0fe-434c-4874-9281-becf2798dc73", "metadata": {}, "source": ["# Allora Forge Signal Miner\n", "\n", "This notebook with help you get started with a randomized grid search,\n", "looking for parameters over a grid of possible values.\n", "\n", "## In this notebook you will quickly be able to:\n", "\n", "  1. Load training and validation, and test data.\n", "  2. Initialize, train and evaluate a variety of LightGBM models.\n", "  3. Choose the best model, and retrain on all the data.\n", "  4. Package your predict function into a `.pkl` file\n", "  5. (TODO: Run your worker to deliver inference to the network)\n", "\n", "## What you will need\n", "\n", "  1. Allora Data API Key (go to: https://developer.allora.network/, register and generate key.)\n", "  2. (Allora Network Wallet Address for live predictions) - under construction\n", "  3. (Forge Competition Topic ID for live predictions) - under construction\n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "4b249db4", "metadata": {}, "outputs": [], "source": ["# Bootstrap\n", "%pip install -q allora_sdk lightgbm pandas numpy matplotlib\n", "\n", "# Optional display-only sanity echo\n", "import os\n", "if os.getenv(\"ALLORA_WALLET_ADDR\"):\n", "    print(f\"Sanity (display only): ALLORA_WALLET_ADDR={os.getenv('ALLORA_WALLET_ADDR')}\")"]}, {"cell_type": "code", "execution_count": null, "id": "24c374ee-d3ca-4b9a-8a01-9719bf042361", "metadata": {}, "outputs": [], "source": ["'''\n", "Write Imports\n", "'''\n", "\n", "from allora_forge_builder_kit import AlloraMLWorkflow #Allora Forge\n", "from allora_forge_builder_kit import get_api_key\n", "import lightgbm as lgb\n", "import pandas as pd\n", "import dill\n", "import time\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from sklearn.model_selection import ParameterSampler"]}, {"cell_type": "code", "execution_count": null, "id": "09b421eb-019f-4307-b574-68cf64d7c532", "metadata": {}, "outputs": [], "source": ["'''\n", "API KEY\n", "This gives you access to OHLCV (open, high, low, close, volume) candle data through the workflow\n", "\n", "To get your API key, go to https://developer.allora.network/, \n", "create an account, and generate a new API key.\n", "\n", "'''\n", "\n", "api_key = get_api_key()"]}, {"cell_type": "code", "execution_count": null, "id": "d84a3fab-4dc4-4173-b5e1-6f5e863fd226", "metadata": {}, "outputs": [], "source": ["'''\n", "Setup\n", "\n", "These variables define the ticker data to retrieve, and the feature and targets sizes.\n", "\n", "hours_needed: \n", "'''\n", "tickers = [\"btcusd\", \"ethusd\", \"solusd\"]\n", "hours_needed = 1*24             # Number of historical hours for feature lookback window\n", "number_of_input_candles = 24    # Number of candles for input features\n", "target_length = 1*24            # Number of hours into the future for target\n", "\n", "# Instantiate the workflow\n", "workflow = AlloraMLWorkflow(\n", "    data_api_key=api_key,\n", "    tickers=tickers,\n", "    hours_needed=hours_needed,\n", "    number_of_input_candles=number_of_input_candles,\n", "    target_length=target_length\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "7babacab-f6cf-4559-957e-279ae0ae4305", "metadata": {}, "outputs": [], "source": ["# Get training, validation, and test data\n", "X_train, y_train, X_val, y_val, X_test, y_test = workflow.get_train_validation_test_data(\n", "    from_month=\"2023-01\",\n", "    validation_months=3,\n", "    test_months=3\n", ")\n", "\n", "# Example: Check the shapes of the datasets\n", "print(\"Training set:\", X_train.shape, y_train.shape)\n", "print(\"Validation set:\", X_val.shape, y_val.shape)\n", "print(\"Test set:\", X_test.shape, y_test.shape)"]}, {"cell_type": "code", "execution_count": null, "id": "3fe9faa0-7af6-41fc-8553-bb51caccf03d", "metadata": {}, "outputs": [], "source": ["'''\n", "Visualize Features and Past Price Process\n", "\n", "The Features are the input data used for training the model, \n", "while the Past Price Process shows the historical price movements of the asset.\n", "\n", "Currently, the features are just the normalized OHLCV (open, high, low, close, volume) data for the last 24 hours.\n", "However, you can choose a different history length by changing the `hours_needed` variable above, \n", "or the number of candles by changing `number_of_input_candles`.\n", "\n", "'''\n", "\n", "eth_data = X_train.loc[(slice(None), 'ethusd'), :]\n", "data_idx = -10000  # which data point to visualize\n", "\n", "# Plot features based on data_idx\n", "plt.plot([eth_data.iloc[data_idx][f\"feature_open_{i}\"] for i in range(number_of_input_candles)], 'o', label=\"open\")\n", "plt.plot([eth_data.iloc[data_idx][f\"feature_high_{i}\"] for i in range(number_of_input_candles)], 'o', label=\"high\")\n", "plt.plot([eth_data.iloc[data_idx][f\"feature_low_{i}\"] for i in range(number_of_input_candles)], 'o', label=\"low\")\n", "plt.plot([eth_data.iloc[data_idx][f\"feature_close_{i}\"] for i in range(number_of_input_candles)], 'o', label=\"close\")\n", "plt.legend()\n", "\n", "# Plot past price process based on data_idx\n", "plt.twiny()\n", "plt.plot(\n", "    (eth_data.iloc[data_idx - (hours_needed * 12):data_idx]['close'].values) / eth_data.iloc[data_idx]['close'],\n", "    label=\"5 min close (past)\"\n", ")\n", "plt.legend(loc='center left')\n", "plt.title(\"Features\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "973a8646-10e1-49ef-ba2c-19035d83eca1", "metadata": {}, "outputs": [], "source": ["'''\n", "LightGBM Randomized Grid Search\n", "\n", "This section performs a randomized grid search to optimize hyperparameters for a LightGBM model.\n", "\n", "The code generate random combinations of hyperparameters from a defined search space, \n", "trains a LightGBM model for each combination, \n", "and evaluates the model's performance on validation and test datasets,\n", "storing the results for comparison.\n", "'''\n", "\n", "n_random_samples = 200  # Number of random parameter settings to evaluate\n", "\n", "#define feature columns\n", "feature_cols = [f for f in list(X_train) if 'feature' in f]\n", "\n", "# Define custom evaluation metric for correlation\n", "def corr_eval_metric(y_true, y_pred):\n", "    corr = np.corrcoef(y_true, y_pred)[0, 1]\n", "    # LightGBM expects: (eval_name, eval_result, is_higher_better)\n", "    return 'corr', corr, True\n", "\n", "# Define search space\n", "param_space = {\n", "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n", "    'learning_rate': [0.0001, 0.001, 0.01, 0.1],\n", "    'L2_reg': [1, 10, 100, 1000],\n", "    'min_child_weight': [10, 100, 1000],\n", "    'num_bins': [8, 16, 32, 64],\n", "    'num_leaves': [4,8,16,32,64],\n", "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n", "}\n", "\n", "# Initialize a list to store results\n", "results = []\n", "\n", "# Randomly sample parameter combinations\n", "random_param_combinations = list(ParameterSampler(param_space, n_iter=n_random_samples, random_state=42))\n", "\n", "for params in random_param_combinations:\n", "    model = lgb.LGBMRegressor(\n", "        n_estimators=1000,\n", "        learning_rate=params['learning_rate'],\n", "        max_depth=params['max_depth'],\n", "        num_leaves=params['num_leaves'],\n", "        reg_lambda=params['L2_reg'],\n", "        min_child_weight=params['min_child_weight'],\n", "        max_bin=params['num_bins'],\n", "        colsample_bytree=params['colsample_bytree']\n", "    )\n", "    \n", "    # Fit model on training data and validate\n", "    model.fit(\n", "        X_train[feature_cols], y_train,\n", "        eval_set=[(X_val[feature_cols], y_val)],\n", "        eval_metric=corr_eval_metric,\n", "        callbacks=[\n", "            lgb.early_stopping(stopping_rounds=100, verbose=False)\n", "        ]\n", "    )\n", "    \n", "    # Get predictions on validation set\n", "    val_preds = model.predict(X_val[feature_cols])\n", "    val_corr = np.corrcoef(y_val, val_preds)[0, 1]\n", "    val_directional_accuracy = np.mean((np.sign(val_preds) == np.sign(y_val)).astype(int))\n", "    \n", "    # Get the best iteration\n", "    best_iteration = model.best_iteration_\n", "    \n", "    # Retrain the model on training + validation data\n", "    retrained_model = lgb.LGBMRegressor(\n", "        n_estimators=best_iteration,\n", "        learning_rate=params['learning_rate'],\n", "        max_depth=params['max_depth'],\n", "        num_leaves=params['num_leaves'],\n", "        reg_lambda=params['L2_reg'],\n", "        min_child_weight=params['min_child_weight'],\n", "        max_bin=params['num_bins'],\n", "        colsample_bytree=params['colsample_bytree']\n", "    )\n", "    retrained_model.fit(\n", "        pd.concat([X_train[feature_cols], X_val[feature_cols]]), \n", "        pd.concat([y_train, y_val])\n", "    )\n", "    \n", "    # Evaluate on the test set\n", "    test_preds = retrained_model.predict(X_test[feature_cols])\n", "    test_corr = np.corrcoef(y_test, test_preds)[0, 1]\n", "    test_directional_accuracy = np.mean((np.sign(test_preds) == np.sign(y_test)).astype(int))\n", "    \n", "    # Record results\n", "    results.append({\n", "        'n_estimators': best_iteration,\n", "        'max_depth': params['max_depth'],\n", "        'learning_rate': params['learning_rate'],\n", "        'L2_reg': params['L2_reg'],\n", "        'min_child_weight': params['min_child_weight'],\n", "        'num_bins': params['num_bins'],\n", "        'num_leaves': params['num_leaves'],\n", "        'colsample_bytree': params['colsample_bytree'],\n", "        'val_corr': val_corr,\n", "        'val_directional_accuracy': val_directional_accuracy,\n", "        'test_corr': test_corr,\n", "        'test_directional_accuracy': test_directional_accuracy\n", "    })\n", "\n", "# Convert results to a DataFrame\n", "results_df = pd.DataFrame(results)\n", "print(results_df)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "df0ef775", "metadata": {}, "outputs": [], "source": ["'''\n", "Inspect Results\n", "\n", "Compare validation and test scores, making sure higher validation scores correspond to higher test scores.\n", "\n", "This will give you confidence that the model is generalizing well and not overfitting to the validation set.\n", "Even though, notice that there is no guarantee that the best model on validation\n", "will be the best on test, but it is a good indicator.\n", "\n", "If you see a weak correlation between validation and test scores,\n", "something like a round ball, or a negative trend,\n", "it indicates that the model is not generalizing well,\n", "and you should use caution when selecting hyperparameters based on validation performance.\n", "'''\n", "\n", "plt.scatter(results_df['val_corr'], results_df['test_corr'])\n", "plt.xlabel('Validation Correlation')\n", "plt.ylabel('Test Correlation')\n", "\n", "\n", "#plot linear fit line\n", "m, b = np.polyfit(results_df['val_corr'], results_df['test_corr'], 1)\n", "trend = 'positive' if m > 0 else 'negative'\n", "performance_correlation = np.corrcoef(results_df['val_corr'], results_df['test_corr'])[0, 1]\n", "plt.title(f'Validation vs Test Correlation \\n Trend: {trend} (slope={m:.2f}), Correlation: {performance_correlation:.2f}')\n", "\n", "plt.plot(results_df['val_corr'], m*results_df['val_corr'] + b, color='red')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "1dd7cc8d", "metadata": {}, "outputs": [], "source": ["results_df"]}, {"cell_type": "code", "execution_count": null, "id": "eaf3938f", "metadata": {}, "outputs": [], "source": ["'''\n", "Choose Model is Higher Average validation and test correlation\n", "\n", "Retrain the model on all the data, using the best hyperparameters found.\n", "'''\n", "best_index = (results_df['val_corr'] + results_df['test_corr']).idxmax()\n", "best_params = results_df.loc[best_index]\n", "print(\"Best Hyperparameters:\\n\", best_params)\n", "best_model = lgb.LGBMRegressor(\n", "    n_estimators=int(best_params['n_estimators']),\n", "    learning_rate=best_params['learning_rate'],\n", "    max_depth=int( best_params['max_depth'] ),\n", "    num_leaves=int( best_params['num_leaves'] ),\n", "    reg_lambda=best_params['L2_reg'],\n", "    min_child_weight=int(best_params['min_child_weight']),\n", "    max_bin=int(best_params['num_bins'])\n", ")\n", "best_model.fit(\n", "    pd.concat([X_train[feature_cols], X_val[feature_cols], X_test[feature_cols]]), \n", "    pd.concat([y_train, y_val, y_test]),\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "470116dc-3269-4d1b-b3ee-fd24af532ebf", "metadata": {}, "outputs": [], "source": ["'''\n", "Package the model and predict function\n", "'''\n", "\n", "# Final predict function\n", "def predict() -> pd.Series:\n", "    live_features = workflow.get_live_features(\"btcusd\")\n", "    preds = best_model.predict(live_features)\n", "    return pd.Series(preds, index=live_features.index)\n", "\n", "# Pickle the function\n", "with open(\"predict.pkl\", \"wb\") as f:\n", "    dill.dump(predict, f)"]}, {"cell_type": "code", "execution_count": null, "id": "8d4f431e-e3c2-4e29-b3dd-4a2434aa6865", "metadata": {}, "outputs": [], "source": ["'''\n", "Test Live Predictions\n", "\n", "This function simulates a live prediction scenario by loading the pickled function,\n", "calling it, and printing the prediction time and result.\n", "'''\n", "\n", "# Load the pickled predict function\n", "with open(\"predict.pkl\", \"rb\") as f:\n", "    predict_fn = dill.load(f)\n", "\n", "# Call the function and get predictions\n", "tic = time.time()\n", "prediction = predict_fn()\n", "toc = time.time()\n", "\n", "print(\"predict time: \", (toc - tic) )\n", "print(\"prediction: \", prediction )\n"]}, {"cell_type": "code", "execution_count": null, "id": "f87a396f", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "ml311 dev", "language": "python", "name": "ml311_dev"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}